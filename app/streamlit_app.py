# English: Minimal Streamlit demo for NeuroShield-3D (debug-friendly).
# ÙØ§Ø±Ø³ÛŒ: Ø¯Ù…Ùˆ Ù…ÛŒÙ†ÛŒÙ…Ø§Ù„ Ø§Ø³ØªØ±ÛŒÙ…Ù„ÛŒØª Ø¨Ø±Ø§ÛŒ NeuroShield-3D (Ø³Ø§Ø²Ú¯Ø§Ø± Ø¨Ø§ Ø­Ø§Ù„Øª Ø¯ÛŒØ¨Ø§Ú¯).

from __future__ import annotations
from pathlib import Path
from typing import Optional, List
import numpy as np
import streamlit as st
import matplotlib.pyplot as plt
import torch
from torch import amp  # for mixed precision

# Project imports
from src.config.config import PATHS, CFG, get_device
from src.models.unet3d import UNet3D
from src.data_loader.brats_dataset import BratsPatches
from src.utils.viz3d import take_slice

# --------------------------- Helpers / ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ ---------------------------

def find_latest_ckpt() -> Optional[Path]:
    """
    English: Find most recent checkpoint_best.pth (fallback to checkpoint_last.pth).
    ÙØ§Ø±Ø³ÛŒ: Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† Ú†Ú©â€ŒÙ¾ÙˆÛŒÙ†Øª best Ø±Ø§ Ù¾ÛŒØ¯Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ (Ø¯Ø± Ù†Ø¨ÙˆØ¯ØŒ last).
    """
    exp = PATHS.experiments
    if not exp.exists():
        return None
    cands: List[Path] = []
    for run in exp.glob("*"):
        if not run.is_dir():
            continue
        best = run / "checkpoint_best.pth"
        last = run / "checkpoint_last.pth"
        if best.exists(): cands.append(best)
        elif last.exists(): cands.append(last)
    if not cands:
        return None
    cands.sort(key=lambda p: p.stat().st_mtime, reverse=True)
    return cands[0]

@st.cache_resource(show_spinner=False)
def load_model() -> tuple[UNet3D, str]:
    """
    English: Build model and load latest checkpoint if present.
    ÙØ§Ø±Ø³ÛŒ: Ù…Ø¯Ù„ Ø±Ø§ Ù…ÛŒâ€ŒØ³Ø§Ø²Ø¯ Ùˆ Ø§Ú¯Ø± Ú†Ú©â€ŒÙ¾ÙˆÛŒÙ†ØªÛŒ Ø¨Ø§Ø´Ø¯ Ø¢Ù† Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    device_str = get_device()
    device = torch.device(device_str)
    model = UNet3D(in_channels=CFG.in_channels, out_channels=CFG.out_channels, base=16).to(device)
    ckpt = find_latest_ckpt()
    if ckpt is not None and ckpt.exists():
        data = torch.load(ckpt, map_location=device)
        state = data.get("state_dict", data)
        try:
            model.load_state_dict(state, strict=True)
            status = f"âœ… Loaded checkpoint: {ckpt.name}"
        except Exception as e:
            status = f"âš ï¸ Could not load checkpoint ({ckpt.name}): {e}"
    else:
        status = "âš ï¸ No checkpoint found â€” using random weights."
    model.eval()
    return model, status

def get_debug_sample() -> tuple[np.ndarray, np.ndarray]:
    """
    English: Create a synthetic sample using BratsPatches(debug=True).
    ÙØ§Ø±Ø³ÛŒ: ØªÙˆÙ„ÛŒØ¯ Ù†Ù…ÙˆÙ†Ù‡Ù” Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¨Ø§ BratsPatches Ø¯Ø± Ø­Ø§Ù„Øª Ø¯ÛŒØ¨Ø§Ú¯.
    """
    ds = BratsPatches(root=PATHS.data_processed / "val",
                      patch_size=CFG.img_size, debug=True, debug_len=1)
    batch = ds[0]
    img = batch["image"].numpy()  # [C,D,H,W]
    msk = batch["mask"].numpy()   # [D,H,W]
    return img, msk

def run_inference(model: UNet3D, image: np.ndarray) -> np.ndarray:
    """
    English: Run model inference on one sample image [C,D,H,W] -> preds [D,H,W].
    ÙØ§Ø±Ø³ÛŒ: Ø§Ø¬Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…Ø¯Ù„ Ø±ÙˆÛŒ ÛŒÚ© Ù†Ù…ÙˆÙ†Ù‡ [C,D,H,W] Ùˆ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ù…Ø§Ø³Ú© Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ [D,H,W].
    """
    device = next(model.parameters()).device
    x = torch.from_numpy(image[None, ...]).to(device)  # [1,C,D,H,W]
    use_amp = (device.type == "cuda") and CFG.amp
    with torch.no_grad(), amp.autocast("cuda", enabled=use_amp):
        logits = model(x)                               # [1,C,D,H,W]
        preds = torch.argmax(logits, dim=1)[0].cpu().numpy().astype(np.int16)
    return preds

def plot_overlay(slice_img: np.ndarray, slice_mask: np.ndarray | None, title: str):
    """
    English: Show grayscale slice with optional mask overlay.
    ÙØ§Ø±Ø³ÛŒ: Ù†Ù…Ø§ÛŒØ´ Ø§Ø³Ù„Ø§ÛŒØ³ Ø®Ø§Ú©Ø³ØªØ±ÛŒ Ø¨Ø§ Ø§Ù…Ú©Ø§Ù† Ø§ÙˆØ±Ù„ÛŒ Ù…Ø§Ø³Ú©.
    """
    fig = plt.figure(figsize=(4, 4))
    plt.imshow(slice_img, cmap="gray")
    if slice_mask is not None:
        # show mask (non-zero) transparently
        overlay = np.ma.masked_where(slice_mask == 0, slice_mask)
        plt.imshow(overlay, alpha=0.4)
    plt.axis("off")
    plt.title(title)
    st.pyplot(fig, clear_figure=True)

# --------------------------- UI / Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ ---------------------------

st.set_page_config(page_title="NeuroShield-3D Demo", layout="wide")
st.title("ğŸ§  NeuroShield-3D â€¢ MRI Tumor Segmentation (Demo)")

with st.sidebar:
    st.header("Settings / ØªÙ†Ø¸ÛŒÙ…Ø§Øª")
    axis_name = st.selectbox("Slice axis / Ù…Ø­ÙˆØ± Ø§Ø³Ù„Ø§ÛŒØ³", ["Z (axial)", "Y (coronal)", "X (sagittal)"], index=0)
    axis = {"Z (axial)":2, "Y (coronal)":1, "X (sagittal)":0}[axis_name]  # our array is [C,D,H,W]
    chan_name = st.selectbox("Modality channel / Ú©Ø§Ù†Ø§Ù„ ÙˆØ±ÙˆØ¯ÛŒ", ["T1", "T1ce", "T2", "FLAIR"], index=3)
    chan = ["T1","T1ce","T2","FLAIR"].index(chan_name)

st.markdown("Ø§ÛŒÙ† Ø¯Ù…Ùˆ ÙØ¹Ù„Ø§Ù‹ Ø¨Ø§ **Ù†Ù…ÙˆÙ†Ù‡Ù” Ù…ØµÙ†ÙˆØ¹ÛŒ (Debug)** Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø¨Ù‡â€ŒØ²ÙˆØ¯ÛŒ ÙˆØ±ÙˆØ¯ÛŒ NIfTI/ZIP Ù‡Ù… Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ….")

# Load model once
model, status = load_model()
st.caption(status)

# Prepare sample (debug)
img, msk = get_debug_sample()               # img [C,D,H,W], msk [D,H,W]
shape = img.shape[1:]                       # (D,H,W)
st.write(f"Patch shape: **{shape}**  |  Channels: **{img.shape[0]}**")

# Slice selector
max_index = shape[axis] - 1
idx = st.slider("Slice index / Ø´Ù…Ø§Ø±Ù‡ Ø§Ø³Ù„Ø§ÛŒØ³", min_value=0, max_value=int(max_index), value=int(max_index//2), step=1)

# Extract slices
# English: image is [C,D,H,W]; convert axis to (D,H,W) order indexing.
# ÙØ§Ø±Ø³ÛŒ: ØªØµÙˆÛŒØ± [C,D,H,W] Ø§Ø³ØªØ› Ø§Ù†Ø¯ÛŒØ³â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø±ÙˆÛŒ (D,H,W).
vol = img[chan]                    # [D,H,W]
sl_img = take_slice(vol, axis=axis, index=idx)
sl_gt  = take_slice(msk, axis=axis, index=idx)

col1, col2, col3 = st.columns(3)

with col1:
    plot_overlay(sl_img, None, f"{chan_name} â€¢ Slice {idx}")

# Run inference button
if st.button("Run Inference / Ø§Ø¬Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ", type="primary"):
    preds = run_inference(model, img)      # [D,H,W]
    sl_pr = take_slice(preds, axis=axis, index=idx)
    with col2:
        plot_overlay(sl_img, sl_gt, "Ground Truth / Ù…Ø§Ø³Ú© ÙˆØ§Ù‚Ø¹ÛŒ (Ø¯ÛŒØ¨Ø§Ú¯)")
    with col3:
        plot_overlay(sl_img, sl_pr, "Prediction / Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…Ø¯Ù„")
else:
    with col2:
        plot_overlay(sl_img, sl_gt, "Ground Truth / Ù…Ø§Ø³Ú© ÙˆØ§Ù‚Ø¹ÛŒ (Ø¯ÛŒØ¨Ø§Ú¯)")
    with col3:
        st.info("Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒØŒ Ø¯Ú©Ù…Ù‡Ù” Â«Run InferenceÂ» Ø±Ø§ Ø¨Ø²Ù†ÛŒØ¯.")

st.caption("Tip: Ø§Ú¯Ø± Ú†Ú©â€ŒÙ¾ÙˆÛŒÙ†Øª Ø¯Ø± `experiments/` Ø¨Ø§Ø´Ø¯ØŒ Ù…Ø¯Ù„ Ø¨Ù‡â€ŒØ·ÙˆØ± Ø®ÙˆØ¯Ú©Ø§Ø± Ù„ÙˆØ¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
